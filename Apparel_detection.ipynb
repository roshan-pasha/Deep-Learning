{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd,numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linux\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, load_img , img_to_array , array_to_img\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/roshanbtech/Apparel_detection'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with zipfile.ZipFile('/home/roshanbtech/Apparel_detection/train_LbELtWX.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('/home/roshanbtech/Apparel_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with zipfile.ZipFile('/home/roshanbtech/Apparel_detection/test_ScVgIM0.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('/home/roshanbtech/Apparel_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1      9\n",
       "1   2      0\n",
       "2   3      0\n",
       "3   4      3\n",
       "4   5      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>59996</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>59997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>59998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>59999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>60000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label\n",
       "59995  59996      5\n",
       "59996  59997      1\n",
       "59997  59998      3\n",
       "59998  59999      0\n",
       "59999  60000      5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60000 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n",
      "100%|██████████| 60000/60000 [19:55<00:00, 50.18it/s]\n"
     ]
    }
   ],
   "source": [
    "train_img = [] \n",
    "for i in tqdm(range(train_label.shape[0])):\n",
    "    img = load_img('/home/roshanbtech/Apparel_detection/train/'+ str(train_label['id'][i]) + '.png',grayscale= True)\n",
    "#     img = img.resize((128,128))\n",
    "#     img = cv2.resize(img, (224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = img / 255\n",
    "    train_img.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = load_img('/home/roshanbtech/Apparel_detection/train/'+ str(train_label['id'][0]) + '.png', grayscale= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = np.array(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_label['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(train_img,y,train_size = 0.8 ,random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=0,\n",
    "    \n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator()\n",
    "# train_generator = train_datagen.flow_from_dataframe(\n",
    "#     train_df, \n",
    "#     \"/home/roshanbtech/Untitled Folder/train/\", \n",
    "#     x_col='filename',\n",
    "#     y_col='category',\n",
    "#     target_size=IMAGE_SIZE,\n",
    "#     class_mode='categorical',\n",
    "#     batch_size=BATCH_SIZE \n",
    "# )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.16862746],\n",
       "        [0.09803922],\n",
       "        [0.03529412],\n",
       "        [0.03921569],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.08235294],\n",
       "        [0.09803922],\n",
       "        [0.10980392],\n",
       "        [0.11764706],\n",
       "        [0.13333334],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.24705882],\n",
       "        [0.5294118 ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.1882353 ],\n",
       "        [0.5882353 ],\n",
       "        [0.62352943],\n",
       "        [0.67058825],\n",
       "        [0.6       ],\n",
       "        [0.23529412],\n",
       "        [0.25490198],\n",
       "        [0.3019608 ],\n",
       "        [0.4117647 ],\n",
       "        [0.31764707],\n",
       "        [0.01176471],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.02745098],\n",
       "        [0.28235295],\n",
       "        [0.1882353 ],\n",
       "        [0.21960784],\n",
       "        [0.6156863 ],\n",
       "        [1.        ],\n",
       "        [0.80784315],\n",
       "        [0.57254905],\n",
       "        [0.3882353 ],\n",
       "        [0.15686275],\n",
       "        [0.17254902],\n",
       "        [0.16862746],\n",
       "        [0.16862746],\n",
       "        [0.1254902 ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.02745098],\n",
       "        [0.        ],\n",
       "        [0.25490198],\n",
       "        [0.36078432],\n",
       "        [0.43137255],\n",
       "        [0.45882353],\n",
       "        [0.03529412],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.0627451 ],\n",
       "        [0.        ],\n",
       "        [0.14117648],\n",
       "        [0.23529412],\n",
       "        [0.37254903],\n",
       "        [0.28627452],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.07058824],\n",
       "        [0.        ],\n",
       "        [0.21960784],\n",
       "        [0.1882353 ],\n",
       "        [0.14117648],\n",
       "        [0.40392157],\n",
       "        [0.38039216],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.17254902],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01960784],\n",
       "        [0.10980392],\n",
       "        [0.        ],\n",
       "        [0.13333334],\n",
       "        [0.15686275],\n",
       "        [0.        ],\n",
       "        [0.25490198],\n",
       "        [0.5529412 ],\n",
       "        [0.50980395],\n",
       "        [0.02745098],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.3254902 ],\n",
       "        [0.38039216],\n",
       "        [0.09019608],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.02745098],\n",
       "        [0.07450981],\n",
       "        [0.03921569],\n",
       "        [0.09803922],\n",
       "        [0.21176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.19607843],\n",
       "        [0.5372549 ],\n",
       "        [0.54509807],\n",
       "        [0.13333334],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.24705882],\n",
       "        [0.3254902 ],\n",
       "        [0.34509805],\n",
       "        [0.11764706],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.09019608],\n",
       "        [0.10588235],\n",
       "        [0.04705882],\n",
       "        [0.11764706],\n",
       "        [0.07450981],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.16862746],\n",
       "        [0.33333334],\n",
       "        [0.627451  ],\n",
       "        [0.        ],\n",
       "        [0.1254902 ],\n",
       "        [0.29411766],\n",
       "        [0.25490198],\n",
       "        [0.24705882],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.05490196],\n",
       "        [0.38039216],\n",
       "        [0.14117648],\n",
       "        [0.07450981],\n",
       "        [0.17254902],\n",
       "        [0.20392157],\n",
       "        [0.14117648],\n",
       "        [0.00392157],\n",
       "        [0.25490198],\n",
       "        [0.05490196],\n",
       "        [0.60784316],\n",
       "        [0.4509804 ],\n",
       "        [0.20392157],\n",
       "        [0.23529412],\n",
       "        [0.26666668],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.19607843],\n",
       "        [0.40392157],\n",
       "        [0.11764706],\n",
       "        [0.43137255],\n",
       "        [0.34509805],\n",
       "        [0.21960784],\n",
       "        [0.50980395],\n",
       "        [0.5882353 ],\n",
       "        [0.45882353],\n",
       "        [0.29411766],\n",
       "        [0.5764706 ],\n",
       "        [0.43137255],\n",
       "        [0.15294118],\n",
       "        [0.3019608 ],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.18431373],\n",
       "        [0.13333334],\n",
       "        [0.23137255],\n",
       "        [0.25490198],\n",
       "        [0.16862746],\n",
       "        [0.15686275],\n",
       "        [0.24705882],\n",
       "        [0.54509807],\n",
       "        [0.5882353 ],\n",
       "        [0.6156863 ],\n",
       "        [0.4745098 ],\n",
       "        [0.25490198],\n",
       "        [0.23529412],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.18431373],\n",
       "        [0.31764707]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.17254902],\n",
       "        [0.        ],\n",
       "        [0.21176471],\n",
       "        [0.21176471],\n",
       "        [0.07450981],\n",
       "        [0.04705882],\n",
       "        [0.04705882],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.3019608 ],\n",
       "        [0.25490198],\n",
       "        [0.18431373],\n",
       "        [0.        ],\n",
       "        [0.18431373],\n",
       "        [0.25490198],\n",
       "        [0.34901962],\n",
       "        [0.31764707]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.14117648],\n",
       "        [0.01176471],\n",
       "        [0.0627451 ],\n",
       "        [0.40784314],\n",
       "        [0.57254905],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.14117648],\n",
       "        [0.4509804 ],\n",
       "        [0.14117648],\n",
       "        [0.16862746],\n",
       "        [0.29411766],\n",
       "        [0.3254902 ],\n",
       "        [0.21960784],\n",
       "        [0.15686275],\n",
       "        [0.10980392]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.14117648],\n",
       "        [0.7647059 ],\n",
       "        [0.7294118 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.28627452],\n",
       "        [0.1254902 ],\n",
       "        [0.0627451 ],\n",
       "        [0.5137255 ],\n",
       "        [0.5882353 ],\n",
       "        [0.38039216],\n",
       "        [0.        ],\n",
       "        [0.1254902 ],\n",
       "        [0.14117648]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.3372549 ],\n",
       "        [0.8627451 ],\n",
       "        [0.75686276],\n",
       "        [0.10588235],\n",
       "        [0.        ],\n",
       "        [0.18431373],\n",
       "        [0.16862746],\n",
       "        [0.49411765],\n",
       "        [0.34901962],\n",
       "        [0.        ],\n",
       "        [0.37254903],\n",
       "        [0.3254902 ],\n",
       "        [0.09803922],\n",
       "        [0.10980392]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.3254902 ],\n",
       "        [0.7921569 ],\n",
       "        [0.4862745 ],\n",
       "        [0.10980392],\n",
       "        [0.60784316],\n",
       "        [0.8352941 ],\n",
       "        [0.02745098],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01960784],\n",
       "        [0.36078432],\n",
       "        [0.14117648],\n",
       "        [0.07058824]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.07450981],\n",
       "        [0.        ],\n",
       "        [0.33333334],\n",
       "        [0.8509804 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.11764706],\n",
       "        [0.17254902],\n",
       "        [0.0627451 ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.11764706],\n",
       "        [0.4862745 ],\n",
       "        [0.7411765 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.10588235],\n",
       "        [0.23137255],\n",
       "        [0.02745098]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.03921569],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09803922],\n",
       "        [0.4745098 ],\n",
       "        [0.81960785],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.11764706],\n",
       "        [0.25490198],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.15294118],\n",
       "        [0.20392157],\n",
       "        [0.07450981],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.24705882],\n",
       "        [0.5137255 ],\n",
       "        [0.09019608],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.13333334],\n",
       "        [0.24705882],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.16862746],\n",
       "        [0.        ],\n",
       "        [0.04705882],\n",
       "        [0.07058824],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.11764706],\n",
       "        [0.5529412 ],\n",
       "        [0.42352942],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.15294118],\n",
       "        [0.29411766],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.15294118],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01960784],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.0627451 ],\n",
       "        [0.3372549 ],\n",
       "        [0.7019608 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.13333334],\n",
       "        [0.28627452],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01960784],\n",
       "        [0.        ],\n",
       "        [0.38039216],\n",
       "        [0.34509805],\n",
       "        [0.23137255],\n",
       "        [0.50980395],\n",
       "        [0.18431373],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.03921569],\n",
       "        [0.28235295],\n",
       "        [0.72156864],\n",
       "        [0.1254902 ],\n",
       "        [0.        ],\n",
       "        [0.01960784],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.14117648],\n",
       "        [0.3019608 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.30980393],\n",
       "        [0.38039216],\n",
       "        [0.34901962],\n",
       "        [0.30980393],\n",
       "        [0.21960784],\n",
       "        [0.30980393],\n",
       "        [0.4117647 ],\n",
       "        [0.42352942],\n",
       "        [0.44313726],\n",
       "        [0.29411766],\n",
       "        [0.3372549 ],\n",
       "        [0.4745098 ],\n",
       "        [0.50980395],\n",
       "        [0.63529414],\n",
       "        [0.25490198],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01960784],\n",
       "        [0.        ],\n",
       "        [0.14117648],\n",
       "        [0.36078432],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.09019608],\n",
       "        [0.14117648],\n",
       "        [0.1882353 ],\n",
       "        [0.21960784],\n",
       "        [0.26666668],\n",
       "        [0.21176471],\n",
       "        [0.23529412],\n",
       "        [0.24705882],\n",
       "        [0.21960784],\n",
       "        [0.3019608 ],\n",
       "        [0.44313726],\n",
       "        [0.36862746],\n",
       "        [0.20392157],\n",
       "        [0.04705882],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.02745098],\n",
       "        [0.        ],\n",
       "        [0.30980393],\n",
       "        [0.67058825],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization,GlobalAveragePooling2D,AveragePooling2D\n",
    "from keras.optimizers import adam,SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAST_RUN = False\n",
    "IMAGE_WIDTH=28\n",
    "IMAGE_HEIGHT=28\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS= 1\n",
    "BATCH_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 11, 11, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 166,794\n",
      "Trainable params: 165,322\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "CPU times: user 404 ms, sys: 12 ms, total: 416 ms\n",
      "Wall time: 410 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10, activation='softmax')) # 10 because we have 10 classes 0-9\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28,28,1)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,625,866\n",
      "Trainable params: 1,625,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding = 'same', input_shape=(28,28,1)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),padding = 'same', activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding ='valid'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 124s 3ms/step - loss: 0.4605 - accuracy: 0.8367 - val_loss: 0.2821 - val_accuracy: 0.8932\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 126s 3ms/step - loss: 0.3075 - accuracy: 0.8903 - val_loss: 0.2482 - val_accuracy: 0.9064\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 122s 3ms/step - loss: 0.2628 - accuracy: 0.9041 - val_loss: 0.2283 - val_accuracy: 0.9172\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 128s 3ms/step - loss: 0.2273 - accuracy: 0.9145 - val_loss: 0.2182 - val_accuracy: 0.9172\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 129s 3ms/step - loss: 0.2072 - accuracy: 0.9229 - val_loss: 0.2037 - val_accuracy: 0.9241\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 122s 3ms/step - loss: 0.1864 - accuracy: 0.9305 - val_loss: 0.2085 - val_accuracy: 0.9240\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 119s 2ms/step - loss: 0.1685 - accuracy: 0.9369 - val_loss: 0.2081 - val_accuracy: 0.9257\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 121s 3ms/step - loss: 0.1568 - accuracy: 0.9411 - val_loss: 0.2010 - val_accuracy: 0.9285\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 117s 2ms/step - loss: 0.1454 - accuracy: 0.9449 - val_loss: 0.2059 - val_accuracy: 0.9287\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 126s 3ms/step - loss: 0.1354 - accuracy: 0.9486 - val_loss: 0.2198 - val_accuracy: 0.9269\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 124s 3ms/step - loss: 0.1267 - accuracy: 0.9523 - val_loss: 0.2405 - val_accuracy: 0.9256\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 122s 3ms/step - loss: 0.1228 - accuracy: 0.9543 - val_loss: 0.2144 - val_accuracy: 0.9288\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 132s 3ms/step - loss: 0.1133 - accuracy: 0.9572 - val_loss: 0.2411 - val_accuracy: 0.9285\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 116s 2ms/step - loss: 0.1101 - accuracy: 0.9592 - val_loss: 0.2318 - val_accuracy: 0.9245\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 121s 3ms/step - loss: 0.1011 - accuracy: 0.9611 - val_loss: 0.2490 - val_accuracy: 0.9310\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 123s 3ms/step - loss: 0.1028 - accuracy: 0.9614 - val_loss: 0.2545 - val_accuracy: 0.9303\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 118s 2ms/step - loss: 0.0969 - accuracy: 0.9634 - val_loss: 0.2501 - val_accuracy: 0.9282\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 119s 2ms/step - loss: 0.0936 - accuracy: 0.9642 - val_loss: 0.2368 - val_accuracy: 0.9292\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 119s 2ms/step - loss: 0.0879 - accuracy: 0.9664 - val_loss: 0.2517 - val_accuracy: 0.9320\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 119s 2ms/step - loss: 0.0871 - accuracy: 0.9672 - val_loss: 0.2496 - val_accuracy: 0.9313\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 122s 3ms/step - loss: 0.0842 - accuracy: 0.9685 - val_loss: 0.2592 - val_accuracy: 0.9330\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 124s 3ms/step - loss: 0.0838 - accuracy: 0.9691 - val_loss: 0.2746 - val_accuracy: 0.9285\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 119s 2ms/step - loss: 0.0803 - accuracy: 0.9711 - val_loss: 0.2868 - val_accuracy: 0.9291\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 115s 2ms/step - loss: 0.0797 - accuracy: 0.9706 - val_loss: 0.2965 - val_accuracy: 0.9322\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 122s 3ms/step - loss: 0.0765 - accuracy: 0.9710 - val_loss: 0.2598 - val_accuracy: 0.9323\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 122s 3ms/step - loss: 0.0750 - accuracy: 0.9718 - val_loss: 0.2959 - val_accuracy: 0.9330\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 115s 2ms/step - loss: 0.0764 - accuracy: 0.9722 - val_loss: 0.2954 - val_accuracy: 0.9329\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 125s 3ms/step - loss: 0.0734 - accuracy: 0.9732 - val_loss: 0.3180 - val_accuracy: 0.9345\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 121s 3ms/step - loss: 0.0697 - accuracy: 0.9744 - val_loss: 0.3072 - val_accuracy: 0.9329\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 123s 3ms/step - loss: 0.0701 - accuracy: 0.9743 - val_loss: 0.3379 - val_accuracy: 0.9316\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 119s 2ms/step - loss: 0.0727 - accuracy: 0.9728 - val_loss: 0.2732 - val_accuracy: 0.9344\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 115s 2ms/step - loss: 0.0659 - accuracy: 0.9753 - val_loss: 0.2882 - val_accuracy: 0.9289\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 130s 3ms/step - loss: 0.0680 - accuracy: 0.9751 - val_loss: 0.3027 - val_accuracy: 0.9323\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 119s 2ms/step - loss: 0.0652 - accuracy: 0.9759 - val_loss: 0.2836 - val_accuracy: 0.9327\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 121s 3ms/step - loss: 0.0649 - accuracy: 0.9769 - val_loss: 0.2839 - val_accuracy: 0.9306\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 119s 2ms/step - loss: 0.0658 - accuracy: 0.9757 - val_loss: 0.3111 - val_accuracy: 0.9323\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 120s 3ms/step - loss: 0.0606 - accuracy: 0.9780 - val_loss: 0.3435 - val_accuracy: 0.9313\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 116s 2ms/step - loss: 0.0649 - accuracy: 0.9767 - val_loss: 0.2921 - val_accuracy: 0.9348\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 116s 2ms/step - loss: 0.0605 - accuracy: 0.9779 - val_loss: 0.3479 - val_accuracy: 0.9295\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 119s 2ms/step - loss: 0.0638 - accuracy: 0.9775 - val_loss: 0.3586 - val_accuracy: 0.9312\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 122s 3ms/step - loss: 0.0614 - accuracy: 0.9782 - val_loss: 0.2901 - val_accuracy: 0.9352\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 119s 2ms/step - loss: 0.0618 - accuracy: 0.9783 - val_loss: 0.2814 - val_accuracy: 0.9333\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 119s 2ms/step - loss: 0.0595 - accuracy: 0.9794 - val_loss: 0.3405 - val_accuracy: 0.9341\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 119s 2ms/step - loss: 0.0578 - accuracy: 0.9785 - val_loss: 0.2911 - val_accuracy: 0.9331\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 118s 2ms/step - loss: 0.0598 - accuracy: 0.9789 - val_loss: 0.3206 - val_accuracy: 0.9361\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 123s 3ms/step - loss: 0.0547 - accuracy: 0.9798 - val_loss: 0.3185 - val_accuracy: 0.9330\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 127s 3ms/step - loss: 0.0580 - accuracy: 0.9801 - val_loss: 0.3161 - val_accuracy: 0.9352\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 118s 2ms/step - loss: 0.0567 - accuracy: 0.9795 - val_loss: 0.3619 - val_accuracy: 0.9333\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 120s 2ms/step - loss: 0.0542 - accuracy: 0.9798 - val_loss: 0.3112 - val_accuracy: 0.9353\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 114s 2ms/step - loss: 0.0557 - accuracy: 0.9802 - val_loss: 0.3381 - val_accuracy: 0.9344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f109c6d2410>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=50 , validation_data= (X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 129s 3ms/step - loss: 0.4848 - accuracy: 0.8298 - val_loss: 0.2831 - val_accuracy: 0.8946\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 123s 3ms/step - loss: 0.3232 - accuracy: 0.8848 - val_loss: 0.2429 - val_accuracy: 0.9082\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 122s 3ms/step - loss: 0.2822 - accuracy: 0.8962 - val_loss: 0.2259 - val_accuracy: 0.9139\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 119s 2ms/step - loss: 0.2517 - accuracy: 0.9088 - val_loss: 0.2231 - val_accuracy: 0.9183\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 128s 3ms/step - loss: 0.2312 - accuracy: 0.9150 - val_loss: 0.2089 - val_accuracy: 0.9227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f109df7d9d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=5 , validation_data= (X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "960/960 [==============================] - 105s 109ms/step - loss: 0.9395 - accuracy: 0.6458 - val_loss: 0.4720 - val_accuracy: 0.8046\n",
      "Epoch 2/10\n",
      "960/960 [==============================] - 102s 107ms/step - loss: 0.6648 - accuracy: 0.7494 - val_loss: 0.4394 - val_accuracy: 0.8384\n",
      "Epoch 3/10\n",
      "960/960 [==============================] - 104s 109ms/step - loss: 0.5980 - accuracy: 0.7771 - val_loss: 0.4558 - val_accuracy: 0.8470\n",
      "Epoch 4/10\n",
      "960/960 [==============================] - 104s 108ms/step - loss: 0.5558 - accuracy: 0.7952 - val_loss: 0.3130 - val_accuracy: 0.8722\n",
      "Epoch 5/10\n",
      "960/960 [==============================] - 102s 107ms/step - loss: 0.5241 - accuracy: 0.8075 - val_loss: 0.3865 - val_accuracy: 0.8776\n",
      "Epoch 6/10\n",
      "960/960 [==============================] - 102s 106ms/step - loss: 0.5040 - accuracy: 0.8159 - val_loss: 0.2750 - val_accuracy: 0.8840\n",
      "Epoch 7/10\n",
      "960/960 [==============================] - 102s 106ms/step - loss: 0.4778 - accuracy: 0.8230 - val_loss: 0.3096 - val_accuracy: 0.8816\n",
      "Epoch 8/10\n",
      "960/960 [==============================] - 98s 102ms/step - loss: 0.4716 - accuracy: 0.8290 - val_loss: 0.1659 - val_accuracy: 0.8842\n",
      "Epoch 9/10\n",
      "533/960 [===============>..............] - ETA: 45s - loss: 0.4595 - accuracy: 0.8302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-99:\n",
      "Process ForkPoolWorker-100:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-192ac5c0fb62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                    \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvalid_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     use_multiprocessing= True)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_datagen.flow(X_train,y_train,batch_size = BATCH_SIZE), \n",
    "                    steps_per_epoch= len(X_train) // BATCH_SIZE, epochs= 10 ,\n",
    "                   validation_data= valid_datagen.flow(X_test,y_test,batch_size = BATCH_SIZE),\n",
    "                    validation_steps = len(X_test) // BATCH_SIZE,\n",
    "                    use_multiprocessing= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "960/960 [==============================] - 102s 106ms/step - loss: 0.8205 - accuracy: 0.6985 - val_loss: 0.5538 - val_accuracy: 0.8202\n",
      "Epoch 2/10\n",
      "960/960 [==============================] - 97s 101ms/step - loss: 0.6121 - accuracy: 0.7705 - val_loss: 0.3627 - val_accuracy: 0.8455\n",
      "Epoch 3/10\n",
      "960/960 [==============================] - 96s 100ms/step - loss: 0.5475 - accuracy: 0.7939 - val_loss: 0.2961 - val_accuracy: 0.8648\n",
      "Epoch 4/10\n",
      "960/960 [==============================] - 97s 101ms/step - loss: 0.5147 - accuracy: 0.8091 - val_loss: 0.4041 - val_accuracy: 0.8637\n",
      "Epoch 5/10\n",
      "960/960 [==============================] - 103s 107ms/step - loss: 0.4885 - accuracy: 0.8194 - val_loss: 0.5616 - val_accuracy: 0.8807\n",
      "Epoch 6/10\n",
      "960/960 [==============================] - 99s 103ms/step - loss: 0.4708 - accuracy: 0.8258 - val_loss: 0.2550 - val_accuracy: 0.8860\n",
      "Epoch 7/10\n",
      "960/960 [==============================] - 101s 105ms/step - loss: 0.4544 - accuracy: 0.8313 - val_loss: 0.3203 - val_accuracy: 0.8934\n",
      "Epoch 8/10\n",
      "960/960 [==============================] - 99s 103ms/step - loss: 0.4354 - accuracy: 0.8387 - val_loss: 0.1982 - val_accuracy: 0.8957\n",
      "Epoch 9/10\n",
      "960/960 [==============================] - 99s 103ms/step - loss: 0.4300 - accuracy: 0.8428 - val_loss: 0.3356 - val_accuracy: 0.8967\n",
      "Epoch 10/10\n",
      "960/960 [==============================] - 101s 105ms/step - loss: 0.4161 - accuracy: 0.8478 - val_loss: 0.2895 - val_accuracy: 0.8989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fd403e02550>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_datagen.flow(X_train,y_train,batch_size = BATCH_SIZE), \n",
    "                    steps_per_epoch= len(X_train) // BATCH_SIZE, epochs= 10 ,\n",
    "                   validation_data= valid_datagen.flow(X_test,y_test,batch_size = BATCH_SIZE),\n",
    "                    validation_steps = len(X_test) // BATCH_SIZE,\n",
    "                    use_multiprocessing= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-62c1e988068a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-193753be380d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id\n",
       "0  60001\n",
       "1  60002\n",
       "2  60003\n",
       "3  60004\n",
       "4  60005"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n",
      "100%|██████████| 10000/10000 [00:41<00:00, 240.34it/s]\n"
     ]
    }
   ],
   "source": [
    "test_img = [] \n",
    "for i in tqdm(range(test_label.shape[0])):\n",
    "    img = load_img('/home/roshanbtech/Apparel_detection/test/'+ str(test_label['id'][i]) + '.png',grayscale= True)\n",
    "#     img = img.resize((,224))\n",
    "    img = img_to_array(img)\n",
    "    img = img / 255\n",
    "    test_img.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = np.array(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_classes(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['label'] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60001</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60005</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label\n",
       "0  60001      9\n",
       "1  60002      2\n",
       "2  60003      1\n",
       "3  60004      1\n",
       "4  60005      6"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAQMUlEQVR4nO3dW4xd9XXH8d+amePxMLbBgy91jDE2mAi3Ek47NWmpKiLalPBi8kALDymVkBypIAUVqUX0IahP9JJGfagiOQ2K2yakqRIED6gBuWkQSoQYqDEGGi6WQwYPMxjfZnyb2+rDHKoJzF57OPvc0vX9SKOZOWv23stnzs/nzPnv//6buwvA/389nW4AQHsQdiAJwg4kQdiBJAg7kERfOw+2wvp9pQbbeUgglQs6q2m/aEvVKoXdzG6R9A+SeiX9k7s/HP38Sg3qBru5yiEBBJ7zA4W1hl/Gm1mvpH+U9DlJOyXdaWY7G90fgNaq8jf7bklvuvsRd5+W9B1Je5rTFoBmqxL2zZJ+vuj70fptv8DM9prZiJmNzOhihcMBqKJK2Jd6E+Aj5966+z53H3b34Zr6KxwOQBVVwj4qacui76+QdKxaOwBapUrYn5e0w8y2mdkKSXdIeqI5bQFotoaH3tx91szulfQDLQy9PeLurzStMwBNVWmc3d2flPRkk3oB0EKcLgskQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IotKSzWZ2VNKkpDlJs+4+3IymADRfpbDXfcbdjzdhPwBaiJfxQBJVw+6SnjKzF8xs71I/YGZ7zWzEzEZmdLHi4QA0qurL+Bvd/ZiZbZD0tJn9j7s/s/gH3H2fpH2StMaGvOLxADSo0jO7ux+rf56Q9Jik3c1oCkDzNRx2Mxs0s9UffC3ps5ION6sxAM1V5WX8RkmPmdkH+/m2u/9HU7oC0HQNh93dj0i6vom9AGghht6AJAg7kARhB5Ig7EAShB1IohkTYYCOsL744etzc0Gx2smcPZdcEtbnz52Lt9+1s3jbg6821FMZntmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2bNbmKIc1EueD+aDsWxJvTu2F9YmbtoYbrvh3+Px5rlTp8N6K5WNo5d5648uLaxtO1hp14V4ZgeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnR6xkHL3Mu79XPJZ+cngm3Pbspl8N61f+1Y8b6qkZ+rZuCevv7InrtTPN7GZ5eGYHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ0/O+mph3Wemw/rszb8R1k9/svj67LX34mNfvPpCXH/qqrD+7qnVhbVLVsb/rpOjxfPNJam29mJYv3T18bB++li8/1YofWY3s0fMbMLMDi+6bcjMnjazN+qf17a2TQBVLedl/Dcl3fKh2x6QdMDdd0g6UP8eQBcrDbu7PyPpxIdu3iNpf/3r/ZJua3JfAJqs0TfoNrr7mCTVP28o+kEz22tmI2Y2MqP47xwArdPyd+PdfZ+7D7v7cE39rT4cgAKNhn3czDZJUv3zRPNaAtAKjYb9CUl31b++S9LjzWkHQKuUjrOb2aOSbpK0zsxGJX1Z0sOSvmtmd0t6W9LtrWwSFfT0huWycfTey+Lx4Ndvj/dvwds0c/3xGukDq+L3eMzi7Xt6iutl217zybGwfuTYurB+8vRgWFdftfXhG1Eadne/s6B0c5N7AdBCnC4LJEHYgSQIO5AEYQeSIOxAEkxxXa5oaWMvGUYpGf6Sz5fU4/1bX/Gv0Wdn432XeOv+nWG9fzxe8rk3mKV6bmvc2yX98aWmR9+LJ1v29Bbfr/Pz8fPciXMDYX1+Ov6d9q+Ohw1rK4r/7WXDnY0uVc0zO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kkWecPRonl8rHysvqkYrLHkfj6FK1sfSJP/3tsD69IR7rvuyl+HLQ80G5b008vfbEyXiaqJ9cEdcvL95/rS/+ndR6q/3Ooum1krRqoHgcfub67fG+f/TfjfXU0FYAfukQdiAJwg4kQdiBJAg7kARhB5Ig7EASecbZq4yTS+GcdOstuVzzbDxWXdZblXH0sT+Lx9End8T7XvlOybLKl8fH9+D0hpUD8Tj71NiqeOer4rHw6DIBU+fj1YkG+uPeVHraRskPBH52y8qwvu1Hje2XZ3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSOKXa5y97PrrkbJrs1vJ/3vBnHSvOF+9TO8128L60Ts2FdbmBkrmVb8VPwRmS1YeLlt2eXqo+L5ZMR0f20rGqvsGSs5fCMzNxb/vC9Px+QWai3u7eK5knv988fZbd4/Gx25Q6TO7mT1iZhNmdnjRbQ+Z2TtmdrD+cWtLugPQNMt5Gf9NSbcscftX3X1X/ePJ5rYFoNlKw+7uz0g60YZeALRQlTfo7jWzQ/WX+YWLbpnZXjMbMbORGcXrXwFonUbD/jVJV0vaJWlM0leKftDd97n7sLsP1xRPPgDQOg2F3d3H3X3O3eclfV3S7ua2BaDZGgq7mS0e6/m8pMNFPwugO5SOs5vZo5JukrTOzEYlfVnSTWa2S5JLOirpi8s6mlVcS7yV49ne+L77tlwR1i9cuzGsv78z/vPm/K/EY9k9wdTr2mQ8Hjx9abzv2dUlc+1rJdcJWFF8foMHY82SdOkV8Trk/bX48XLidPFJAnOzJdcgKOlNJdeF9/Ml5y/0Fm9/fCo+uWH9b11fXHzpx4Wl0rC7+51L3PyNsu0AdBdOlwWSIOxAEoQdSIKwA0kQdiCJ9k5x9WqXRe676srC2vlrN4TbzqyKh1qmB+P/92YHimuTV4Wblk4z7ZmJ631n42EgD1qfXhPve25lXLey0dCBeOqwnS++32em4/t8ekV88FPjq8N6bU3x6dlll7E+eyr4hUuqDcbbr79sKqyfPle8/+vWjYfbjm7YUVibrxU/VnhmB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkuupS0lO33xDXP1E8ZttTclXhC+vjejRWLUkWDCeXHdtKZs/ODsZj3Rc2luwgGoYPpphKUu+p+CFQdr/0rorHwnt6io8/U3K55fNT8dTf3jPxuRP96xs/p6PMzKl4WeWJ+fiOi8b5V9cuhNtG52VY8FDimR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmjrOPv82kFN/sGnC+uzf/x+uP3UG5cX1laOx/9v1Sbj3rxkNejocs1l28YD4VJtKq7P1+J/WzSOP1Myn72ktdL57qUrYfcVbz+04Uy47XWXT8Q7L57WLUka7Cuez97fUzIGvyUuv3thTVjf0B/PZz8xfUlhbfx8vO+BY2cLaz3Txb8QntmBJAg7kARhB5Ig7EAShB1IgrADSRB2IIm2jrP3Tl7UZf91pLD++u7t4fYbdr5XWNv6mycb7kuSLszGc6vHz60qrB0/GV+/fPbUirBeK5mXPV+yLLIHY+U+FE+237X97bC+fmU8Xrx94HhYnwsmxD+47qfhtn/9fjyQ/tT4dWH9X6/9dmFtqDeeKz/nJecnlDjn8f3+g3PFayC8eSFe4vvZSz9RWPPeCteNN7MtZvZDM3vNzF4xsy/Vbx8ys6fN7I3657Vl+wLQOct5GT8r6X53v07SpyXdY2Y7JT0g6YC775B0oP49gC5VGnZ3H3P3F+tfT0p6TdJmSXsk7a//2H5Jt7WqSQDVfaw36MzsKkmfkvScpI3uPiYt/IcgacnF1sxsr5mNmNnI9Pz5at0CaNiyw25mqyR9T9J97h7PYFjE3fe5+7C7D6/oiRfLA9A6ywq7mdW0EPRvufv36zePm9mmen2TpJIpSgA6ybxkiMHMTAt/k59w9/sW3f63kt5394fN7AFJQ+7+59G+1tiQ32A3N6Htj+pdGw8GnLn52rB+ckc8/NV7Q/HQ3jVD8fDTlYPxsODm/rjeq5Jll4N5qjPz8ejqq1ObwvpPjmwL60P/GV9Sed2/HSqszZ8tnqrZDPMHiuepfmb96+G2hyY3h/V3z8bTUN8/WzyFVZJmZ6OlrOPf2bX3FA9f/+TM4zo9+96SD4jljLPfKOkLkl42s4P12x6U9LCk75rZ3ZLelnT7MvYFoENKw+7uz6r4EgeteZoG0HScLgskQdiBJAg7kARhB5Ig7EASpePszdTKcXYA0nN+QGf8xJKjZzyzA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEqVhN7MtZvZDM3vNzF4xsy/Vb3/IzN4xs4P1j1tb3y6ARi1nffZZSfe7+4tmtlrSC2b2dL32VXf/u9a1B6BZlrM++5iksfrXk2b2mqTNrW4MQHN9rL/ZzewqSZ+S9Fz9pnvN7JCZPWJmawu22WtmI2Y2MqOLlZoF0Lhlh93MVkn6nqT73P2MpK9JulrSLi08839lqe3cfZ+7D7v7cE39TWgZQCOWFXYzq2kh6N9y9+9LkruPu/ucu89L+rqk3a1rE0BVy3k33iR9Q9Jr7v73i27ftOjHPi/pcPPbA9Asy3k3/kZJX5D0spkdrN/2oKQ7zWyXJJd0VNIXW9IhgKZYzrvxz0paar3nJ5vfDoBW4Qw6IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEubu7TuY2XuSfrbopnWSjretgY+nW3vr1r4kemtUM3vb6u7rlyq0NewfObjZiLsPd6yBQLf21q19SfTWqHb1xst4IAnCDiTR6bDv6/DxI93aW7f2JdFbo9rSW0f/ZgfQPp1+ZgfQJoQdSKIjYTezW8zsp2b2ppk90IkeipjZUTN7ub4M9UiHe3nEzCbM7PCi24bM7Gkze6P+eck19jrUW1cs4x0sM97R+67Ty5+3/W92M+uV9Lqk35c0Kul5SXe6+6ttbaSAmR2VNOzuHT8Bw8x+V9KUpH9291+r3/Y3kk64+8P1/yjXuvtfdElvD0ma6vQy3vXVijYtXmZc0m2S/kQdvO+Cvv5QbbjfOvHMvlvSm+5+xN2nJX1H0p4O9NH13P0ZSSc+dPMeSfvrX+/XwoOl7Qp66wruPubuL9a/npT0wTLjHb3vgr7aohNh3yzp54u+H1V3rffukp4ysxfMbG+nm1nCRncfkxYePJI2dLifDytdxrudPrTMeNfcd40sf15VJ8K+1FJS3TT+d6O7/7qkz0m6p/5yFcuzrGW822WJZca7QqPLn1fVibCPStqy6PsrJB3rQB9Lcvdj9c8Tkh5T9y1FPf7BCrr1zxMd7uf/dNMy3kstM64uuO86ufx5J8L+vKQdZrbNzFZIukPSEx3o4yPMbLD+xonMbFDSZ9V9S1E/Iemu+td3SXq8g738gm5ZxrtomXF1+L7r+PLn7t72D0m3auEd+bck/WUneijoa7ukl+ofr3S6N0mPauFl3YwWXhHdLelySQckvVH/PNRFvf2LpJclHdJCsDZ1qLff0cKfhockHax/3Nrp+y7oqy33G6fLAklwBh2QBGEHkiDsQBKEHUiCsANJEHYgCcIOJPG/9Wj51r21d7YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "filenames = ['60001.png','60002.png','60003.png','60004.png','60005.png']\n",
    "for file in filenames:\n",
    "    img = load_img('/home/roshanbtech/Apparel_detection/test/' + file,   grayscale= True)\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label\tDescription\n",
    "0\tT-shirt/top\n",
    "1\tTrouser\n",
    "2\tPullover\n",
    "3\tDress\n",
    "4\tCoat\n",
    "5\tSandal\n",
    "6\tShirt\n",
    "7\tSneaker\n",
    "8\tBag\n",
    "9\tAnkle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_dropout_0.4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning -- VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'Datasets/Train'\n",
    "valid_path = 'Datasets/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [128,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3] , weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't train existing weights\n",
    "for layer in vgg.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(vgg.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = Dense(1000, activation='relu')(x)\n",
    "prediction = Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model object\n",
    "model_vgg = Model(inputs=vgg.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                250890    \n",
      "=================================================================\n",
      "Total params: 14,965,578\n",
      "Trainable params: 250,890\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# view the structure of the model\n",
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model_vgg.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=model_vgg.fit_generator(train_datagen.flow(X_train,y_train,batch_size = BATCH_SIZE),\n",
    "                         samples_per_epoch = 8000,\n",
    "                         nb_epoch = 5,\n",
    "                         validation_data = test_set,\n",
    "                         nb_val_samples = 2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/data_utils.py:616: UserWarning: The input 10 could not be retrieved. It could be because a worker has died.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/960 [..............................] - ETA: 8:30:28 - loss: 2.5320 - accuracy: 0.0600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/data_utils.py:616: UserWarning: The input 337 could not be retrieved. It could be because a worker has died.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  2/960 [..............................] - ETA: 8:24:05 - loss: 2.3978 - accuracy: 0.1000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/data_utils.py:616: UserWarning: The input 268 could not be retrieved. It could be because a worker has died.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  3/960 [..............................] - ETA: 8:21:22 - loss: 2.4253 - accuracy: 0.1400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/data_utils.py:616: UserWarning: The input 883 could not be retrieved. It could be because a worker has died.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  4/960 [..............................] - ETA: 8:19:44 - loss: 2.3125 - accuracy: 0.1850"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r = model_vgg.fit_generator(train_datagen.flow(X_train,y_train,batch_size = BATCH_SIZE), \n",
    "                    steps_per_epoch= len(X_train) // BATCH_SIZE, epochs= 50 ,\n",
    "                   validation_data= valid_datagen.flow(X_test,y_test,batch_size = BATCH_SIZE),\n",
    "                    validation_steps = len(X_test) // BATCH_SIZE,\n",
    "                    use_multiprocessing= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of classes \n",
    "num_classes = 10\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    # Get base model: ResNet50 \n",
    "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "    \n",
    "    # freeze the layers in base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # Get the output from the base model \n",
    "    base_model_ouput = base_model.output\n",
    "    \n",
    "    # Adding our own layers at the end\n",
    "    # global average pooling: computes the average of all values in the feature map\n",
    "    x = GlobalAveragePooling2D()(base_model_ouput)\n",
    "    \n",
    "    # fully connected and 5-softmax layer\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax', name='fcnew')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 6 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, None, None, 6 4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, None, None, 6 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, None, None, 2 16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, None, None, 2 16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 2 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, None, None, 6 16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, None, None, 6 36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, None, None, 2 16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 2 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, None, None, 6 16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, None, None, 6 36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, None, None, 2 16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 2 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, None, None, 1 32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, None, None, 1 147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, None, None, 5 66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, None, None, 5 131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 5 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, None, None, 1 65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, None, None, 1 147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, None, None, 5 66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 5 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, None, None, 1 65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, None, None, 1 147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, None, None, 5 66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 5 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, None, None, 1 65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, None, None, 1 147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, None, None, 5 66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 5 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, None, None, 2 131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, None, None, 2 590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, None, None, 1 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, None, None, 1 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 1 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, None, None, 2 262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, None, None, 2 590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, None, None, 1 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 1 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, None, None, 2 262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, None, None, 2 590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, None, None, 1 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 1 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, None, None, 2 262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, None, None, 2 590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, None, None, 1 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, None, None, 2 262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, None, None, 2 590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, None, None, 1 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 1 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, None, None, 2 262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, None, None, 2 590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, None, None, 1 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 1 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, None, None, 5 524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, None, None, 2 2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 2 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 2 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 2 0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          1049088     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "fcnew (Dense)                   (None, 10)           5130        dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 24,641,930\n",
      "Trainable params: 1,054,218\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "# compile it\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# summary of model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "959/960 [============================>.] - ETA: 1s - loss: 0.5476 - accuracy: 0.8023Epoch 1/5\n",
      "Epoch 1/5\n",
      "960/960 [==============================] - 2081s 2s/step - loss: 0.5476 - accuracy: 0.8023 - val_loss: 4.7624 - val_accuracy: 0.1002\n",
      "Epoch 2/5\n",
      "960/960 [==============================] - 2087s 2s/step - loss: 0.4645 - accuracy: 0.8295 - val_loss: 4.6215 - val_accuracy: 0.1002\n",
      "Epoch 3/5\n",
      "960/960 [==============================] - 2103s 2s/step - loss: 0.4401 - accuracy: 0.8378 - val_loss: 6.2063 - val_accuracy: 0.1002\n",
      "Epoch 4/5\n",
      "960/960 [==============================] - 2110s 2s/step - loss: 0.4200 - accuracy: 0.8462 - val_loss: 6.3891 - val_accuracy: 0.1002\n",
      "Epoch 5/5\n",
      "632/960 [==================>...........] - ETA: 9:52 - loss: 0.4048 - accuracy: 0.8478"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/keras/utils/data_utils.py\", line 406, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/numpy_array_iterator.py\", line 153, in _get_batches_of_transformed_samples\n",
      "    x.astype(self.dtype), params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py\", line 870, in apply_transform\n",
      "    order=self.interpolation_order)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/affine_transformations.py\", line 333, in apply_affine_transform\n",
      "    cval=cval) for x_channel in x]\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/affine_transformations.py\", line 333, in <listcomp>\n",
      "    cval=cval) for x_channel in x]\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/scipy/ndimage/interpolation.py\", line 486, in affine_transform\n",
      "    output, order, mode, cval, None, None)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r = model.fit_generator(train_datagen.flow(X_train,y_train,batch_size = BATCH_SIZE), \n",
    "                    steps_per_epoch= len(X_train) // BATCH_SIZE, epochs= 5 ,\n",
    "                   validation_data= valid_datagen.flow(X_test,y_test,batch_size = BATCH_SIZE),\n",
    "                    validation_steps = len(X_test) // BATCH_SIZE,\n",
    "                    use_multiprocessing= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
